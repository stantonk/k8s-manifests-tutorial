apiVersion: v1
# In Kubernetes, a Service is a method for exposing a network application that
# is running as one or more Pods in your cluster. Exposes a set of Pods in a
# Deployment by providing Load Balancing and Network access
kind: Service
metadata:
  name: rest-api
spec:
  # The set of Pods targeted by a Service is usually determined by a selector
  # that you define. Selector label key-value pairs must match
  # Deployment.spec.template.metadata.labels key-value pairs
  selector:
    app: rest-api
  # Service type can be: ClusterIP, NodePort, LoadBalancer, ExternalName
  # ClusterIP: Exposes the service on a cluster-internal IP. The service is accessible only within the cluster.
  # NodePort: Exposes the service externally by opening a specific port on every node in your cluster
  # and forwards traffic from that port to the service.
  # LoadBalancer: Automatically provisions an external load balancer (using your cloud provider’s capabilities)
  # that routes traffic to your service. Internally, it typically relies on a combination of NodePort and ClusterIP.
  type: NodePort
  ports:
    - protocol: TCP
      port: 80
      targetPort: 5000
---
apiVersion: apps/v1
kind: Deployment
# metadata about the Deployment object
metadata:
  name: rest-api
  labels:
    app: rest-api
  annotations:
    version: 0.0.1
# what we want the Deployment's desired state
# to be
spec:
  replicas: 1
  # tells k8s which pods the Deployment manages
  selector:
    # must match spec.template.metadata.labels
    matchLabels:
      app: rest-api
  # The "template" here defines the Pod spec
  # for each replica:
  template:
    metadata:
      labels:
        app: rest-api
    # This section describes what the Pod should
    # run—like the container image, exposed ports,
    # and other configurations.
    spec:

      containers:
      - name: rest-api
        image: rest-api:latest
#        image: alpine:latest
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 5000
          name: svcport
        volumeMounts:
          - mountPath: /etc/config
            name: config-volume
        command: ["python", "/srv/rest.py"]
#        args:
#          - "rest.py"

        startupProbe:
          httpGet:
            port: svcport
            path: /health
          initialDelaySeconds: 1
          failureThreshold: 3
          timeoutSeconds: 3
          periodSeconds: 5
          successThreshold: 1
        # Liveness probes determine when to restart a container. For example, liveness probes could catch a deadlock
        # when an application is running but unable to make progress.
        # If a container fails its liveness probe repeatedly, the kubelet restarts the container.
        # Liveness probes do not wait for readiness probes to succeed. If you want to wait before executing a liveness
        # probe, you can either define initialDelaySeconds or use a startup probe.
        livenessProbe:
          httpGet:
            port: svcport
            path: /health
          successThreshold: 1
          periodSeconds: 10
          timeoutSeconds: 3
          failureThreshold: 3
          initialDelaySeconds: 60

        # Readiness probes determine when a container is ready to start accepting traffic. This is useful when waiting
        # for an application to perform time-consuming initial tasks, such as establishing network connections,
        # loading files, and warming caches.
        # If the readiness probe returns a failed state, Kubernetes removes the pod from all matching service endpoints.
        # Readiness probes run on the container during its whole lifecycle.
        readinessProbe:
          httpGet:
            port: svcport
            path: /health
          initialDelaySeconds: 2
          failureThreshold: 3
          successThreshold: 1
          timeoutSeconds: 3
          periodSeconds: 5

      # volumes declared available to the
      # pod(s)
      volumes:
        # spec.template.spec.volumes[].name
        # must match spec.template.spec.containers[].volumeMounts[].name
        - name: config-volume
          configMap:
            name: config


---
apiVersion: v1
kind: ConfigMap
data:
  config.yaml: |
    some: "config"
    more: config
    enabled: true
    moreconfig: 5
metadata:
  name: config